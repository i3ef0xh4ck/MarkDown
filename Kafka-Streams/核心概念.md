[原文地址](https://kafka.apache.org/10/documentation/streams/core-concepts)
# 核心概念
Kafka Streams是一个客户端库，用于处理和分析存储在Kafka中的数据。 它基于重要的流处理概念，如事件时间和处理时间的恰当区分，窗口化支持，简单高效的应用程序状态管理和实时查询。

Kafka Streams进入门槛低：您可以在单台机器上快速编写和运行一个小规模的概念证明; 而且只需要在多台计算机上运行应用程序的其他实例即可扩展到大批量生产工作负载。 通过利用Kafka的并行模型，Kafka Streams可以透明地处理相同应用程序的多个实例的负载平衡。

Kafka Streams的一些亮点：
- 设计为一个简单轻量级的客户端库，可以轻松嵌入到任何Java应用程序中，并与用户的流媒体应用程序的任何现有打包，部署和操作工具集成。
- 除了Apache Kafka本身作为内部消息传递层之外，没有外部依赖关系; 值得注意的是，它使用Kafka的分区模型来横向扩展处理，同时保持强有力的排序保证。
- 支持容错局部状态，可以实现非常快速有效的有状态操作，如窗口连接和聚合。
- 支持一次处理语义，以确保每个记录只被处理一次，即使在处理过程中出现故障的Streams客户端或Kafka代理中也是如此。
- 采用一次一个记录的处理，以实现毫秒级的处理延迟，并支持基于事件时间的窗口化操作，并且记录较晚到达。
- 提供必要的流处理原语，以及高级Streams DSL和低级Processor API。

我们首先总结一下Kafka Streams的关键概念。

## 流处理拓扑
- 流是Kafka Streams提供的最重要的抽象：它代表一个无限的，不断更新的数据集。 流是一个有序的，可重放的，容错的不可变数据记录序列，其中一个数据记录被定义为一个键值对。
- 流处理应用程序是使用Kafka Streams库的任何程序。 它通过一个或多个处理器拓扑来定义其计算逻辑，其中处理器拓扑是通过流（边）连接的流处理器（节点）的图形。
- 流处理器是处理器拓扑中的一个节点; 它代表一个处理步骤，通过从拓扑中的上游处理器一次接收一个输入记录，将其操作应用于其中，并随后可以向其下游处理器产生一个或多个输出记录，从而变换流中的数据。

拓扑中有两个特殊处理器：
- Source Processor（源处理器）: 源处理器是没有任何上游处理器的特殊类型的流处理器。 它通过从这些主题中消耗记录并将其转发到其下游处理器来从一个或多个Kafka主题产生其拓扑的输入流。
- Sink Processor（宿处理器）：宿处理器是一种特殊类型的流处理器，没有下游处理器。 它将来自上游处理器的任何收到的记录发送到指定的Kafka主题。

请注意，在正常的处理器节点中，还可以在处理当前记录时访问其他远程系统。 因此，处理后的结果可以回传到Kafka或写入外部系统。
![streams-architecture-topology](streams-architecture-topology.jpg)

Kafka Streams提供了两种方法来定义流处理拓扑：Kafka Streams DSL提供了最常用的数据转换操作，如map，filter，join和aggregations(聚合)等。 较低级别的处理器API允许开发人员定义和连接定制处理器以及与状态存储（参考：state）进行交互。

处理器拓扑仅仅是您的流处理代码的逻辑抽象。 在运行时，逻辑拓扑被实例化并在应用程序内部复制以进行并行处理（请参阅流分区和任务以了解详细信息）。

## 时间
流处理的一个关键方面是时间的概念，以及如何建模和整合。 例如，某些操作（如窗口）是基于时间边界来定义的。

时间在流中的常见概念是：
- Event time（事件时间）：事件或数据记录发生时的时间点，即最初在“源”处创建的时间点。 示例：如果事件是由汽车中的GPS传感器报告的地理位置变化，则相关的事件时间将是GPS传感器捕获位置变化的时间。
- Processing time（处理时间）：事件或数据记录正好由流处理应用程序处理的时间点，即正在消耗记录的时间点。 处理时间可能比原始事件时间晚数毫秒，数小时或数天等。 示例：设想一个分析应用程序，该应用程序可读取并处理从汽车传感器报告的地理位置数据，并将其呈现给车队管理仪表板。 这里，分析应用程序中的处理时间可能是事件时间后的几毫秒或几秒（例如基于Apache Kafka和Kafka Streams的实时管道）或几小时（例如，基于Apache Hadoop或Apache Spark的批处理管道）。
- Ingestion time（摄入时间）：由Kafka broker 将事件或数据记录存储在主题分区中的时间点。 与事件时间的不同之处在于，当记录被Kafka broker 附加到目标主题时，而不是在“源代码”创建记录时，会生成此提取时间戳。 处理时间的差异在于处理时间是流处理应用程序处理记录时的时间。 例如，如果一个记录从来没有被处理过，没有处理时间的概念，但是它仍然有一个摄取时间。

事件时间和摄取时间之间的选择实际上是通过配置Kafka（不是Kafka Streams）来完成的：从Kafka 0.10.x开始，时间戳被自动嵌入到Kafka消息中。 根据Kafka的配置，这些时间戳代表事件时间或摄取时间。 可以在 broker 级别或每个主题上指定相应的Kafka配置设置。 Kafka Streams中的默认时间戳提取器将按原样检索这些嵌入的时间戳。 因此，应用程序的有效时间语义取决于这些嵌入式时间戳的有效Kafka配置。

Kafka Streams通过TimestampExtractor接口为每个数据记录分配一个时间戳。 这些每记录时间戳描述了一个流在时间方面的进展，并被诸如窗口操作之类的时间相关操作所利用。 因此，这个时间只有在新的记录到达处理器时才会提前。 我们把这个数据驱动的时间称为应用程序的流时间，以便在应用程序正在执行时与挂钟时间区分开来。 TimestampExtractor接口的具体实现将为流时间定义提供不同的语义。 例如基于数据记录的实际内容（诸如嵌入的时间戳字段）来检索或计算时间戳以提供事件时间语义，并且返回当前的挂钟时间，从而产生处理时间语义以产生时间。 因此，开发人员可以根据自己的业务需求实施不同的时间概念。

最后，只要Kafka Streams应用程序向Kafka写入记录，那么它也会为这些新记录分配时间戳。 时间戳的分配方式取决于上下文：
- 当通过处理某些输入记录（例如，在process（）函数调用中触发的context.forward（））生成新的输出记录时，输出记录时间戳直接从输入记录时间戳继承。
- 当通过周期函数（如Punctuator＃punctuate（））生成新的输出记录时，输出记录时间戳被定义为流任务的当前内部时间（通过context.timestamp（）获得）。
- 对于聚合，生成的聚合更新记录的时间戳将是触发更新的最新到达的输入记录的时间戳。

## 状态
某些流处理应用程序不需要状态，这意味着消息的处理与所有其他消息的处理无关。 但是，能够维护状态为复杂的流处理应用程序提供了许多可能性：您可以加入输入流或分组和汇总数据记录。 Kafka Streams DSL提供了许多这种有状态的运营商。

Kafka Streams提供了所谓的状态存储，可以被流处理应用程序用来存储和查询数据。 这是执行有状态操作时的一个重要功能。 Kafka Streams中的每个任务都嵌入了一个或多个可以通过API访问的状态存储，以存储和查询处理所需的数据。 这些状态存储可以是持久性键值存储，内存中的散列表或其他方便的数据结构。 Kafka Streams为本状态存储提供容错和自动恢复功能。

Kafka Streams允许通过创建状态存储的流处理应用程序外部的方法，线程，进程或应用程序对状态存储进行直接只读查询。 这是通过称为交互式查询的功能提供的。 所有存储都被命名，交互式查询只公开底层实现的读取操作。

## 处理保证

在流处理中，最常见的问题之一是“我的流处理系统是否保证每个记录只处理一次，即使在处理过程中遇到一些故障？对于许多不能承受任何数据丢失或数据重复的应用程序来说，没有能够确保一次流处理是一种破坏行为，在这种情况下，除了流处理管道之外，通常还会使用面向批处理的框架Lambda架构。在0.11.0.0之前，Kafka只提供至少一次的传递保证，因此任何利用它作为后端存储的流处理系统都不能保证端到端只是一次语义。事实上，即使对于声称支持一次处理的流处理系统，只要他们正在读写Kafka作为Source/sink 处理器，他们的应用程序实际上也不能保证在整个流水线中不会产生重复。自0.11.0.0发布以来，Kafka增加了支持，允许其制作者以[事务和幂等](https://kafka.apache.org/documentation/#semantics)的方式发送消息到不同的主题分区，Kafka Streams通过利用这些特性添加了端到端的处理语义。更具体地说，它保证了对于源自卡夫卡主题的任何记录的读取，它的处理结果将在输出的卡夫卡主题中以及在有状态操作的状态存储中准确反映一次。请注意，Kafka Streams之间的主要区别在于，一次保证与其他流处理框架之间的关键保证是Kafka Streams与底层Kafka存储系统紧密集成，并确保提交输入主题偏移，更新状态商店和写入输出主题将完成自动化，而不是将卡夫卡视为可能有副作用的外部系统。要详细了解如何在Kafka Streams内完成这些操作，建议读者阅读[KIP-129](https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics)。为了在运行Kafka Streams应用程序时实现一次语义，用户可以简单地将processing.guarantee配置值设置为exactly_once（默认值是at_least_once）。更多细节可以在[Kafka Streams Configs](https://kafka.apache.org/10/documentation#streamsconfigs)部分找到。
