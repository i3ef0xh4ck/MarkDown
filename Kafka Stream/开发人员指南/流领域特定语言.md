[原文地址](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)

# 流领域特定语言
Kafka Streams DSL（域特定语言）构建在Streams Processor API之上。 这是大多数用户推荐的，特别是初学者。 大多数数据处理操作都可以用几行DSL代码来表示。
## 概述
与处理器API相比，只有DSL支持：
- 内置KStream，KTable和GlobalKTable形式的流和表的抽象。 拥有流和表的一流支持是至关重要的，因为在实践中，大多数用例不仅需要流或数据库/表，而且还需要两者的组合。 例如，如果您的用例是创建实时更新的客户360度视图，那么您的应用程序将会将许多与客户相关的事件输入流转换为包含不断更新的360度视图的输出表 客户的观点。
- 具有[无状态变换](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-transformations-stateless)（例如map和filter）以及诸如聚集（例如count:计数和reduce:减少），连接（例如，leftJoin:左连接）和窗口化（例如session window:会话窗口）的[有状态变换](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-transformations-stateful)的声明性，函数式编程风格。

使用DSL，您可以在应用程序中定义处理器拓扑（即逻辑处理计划）。 完成这个步骤是：
1. 指定[一个或多个从Kafka主题读取的输入流](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-sources)。
2. 在这些流上组合[转换](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-transformations)。
3. 将[结果输出流写回到Kafka主题](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html#streams-developer-guide-dsl-destinations)，或通过[交互式查询](https://kafka.apache.org/10/documentation/streams/developer-guide/interactive-queries.html#streams-developer-guide-interactive-queries)（例如，通过REST API）将应用程序的处理结果直接公开给其他应用程序。

在应用程序运行之后，定义的处理器拓扑结构被连续地执行（即处理计划付诸实施）。 下面提供了使用DSL编写流处理应用程序的分步指南。

有关可用API功能的完整列表，请参阅[Kafka Streams Javadocs](https://kafka.apache.org/10/documentation/streams/javadocs.html#streams-javadocs)。

## 创建来自KAFKA的源流
您可以轻松地从Kafka主题中读取数据到您的应用程序中。 支持以下操作。

从Kafka读取 | 描述
---- | ---
Stream  <br /><br />  input topics → KStream| 从指定的Kafka输入主题创建KStream，并将数据解释为记录流。 KStream表示分区的记录流。 （细节）<br/><br />在KStream的情况下，每个应用程序实例的本地KStream实例将仅填充来自输入主题的一部分分区的数据。 总而言之，在所有应用程序实例中，读取和处理所有输入主题分区。<br /><br />[代码参考](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)<br /><br />如果您没有明确指定SerDes，则使用配置中的默认SerDes。 <br /><br />如果Kafka输入主题中的记录的键或值类型与配置的默认SerDes不匹配，则必须明确指定SerDes。 有关配置默认SerDes，可用SerDes和实现您自己的自定义SerDes的信息，请参阅数据类型和序列化。 <br /><br /> 存在多个流的变体，例如，为输入主题指定正则表达式模式。
Table <br /><br /> input topic → KTable|将指定的Kafka输入主题读入KTable。该主题被解释为更改日志流，其中具有相同键的记录被解释为对于该键的UPSERT aka INSERT / UPDATE（当记录值不为空时）或DELETE（当值为空时）。 （细节）<br /><br />在KStream的情况下，每个应用程序实例的本地KStream实例将仅填充来自输入主题的一部分分区的数据。总而言之，在所有应用程序实例中，读取和处理所有输入主题分区。<br /><br />您必须为该表提供一个名称（更确切地说，对于支持该表的内部状态存储）。这对于支持对表的交互式查询是必需的。如果没有提供名称，表格将不会被查询，并且会为状态存储提供一个内部名称。<br /><br />如果您没有明确指定SerDes，则使用配置中的默认SerDes。<br /><br />如果Kafka输入主题中的记录的键或值类型与配置的默认SerDes不匹配，则必须明确指定SerDes。有关配置默认SerDes，可用SerDes和实现您自己的自定义SerDes的信息，请参阅[数据类型和序列化](https://kafka.apache.org/10/documentation/streams/developer-guide/datatypes.html#streams-developer-guide-serdes)。<br /><br />存在多种表格变体，例如指定从输入主题读取时要使用的auto.offset.reset策略。
Global Table<br /><br />input topic → GlobalKTable|将指定的Kafka输入主题读取到GlobalKTable中。 该主题被解释为更改日志流，其中具有相同键的记录被解释为对于该键的UPSERT aka INSERT / UPDATE（当记录值不为空时）或DELETE（当值为空时）。 （细节）<br /><br />在GlobalKTable的情况下，每个应用程序实例的本地GlobalKTable实例将仅填充来自输入主题的一部分分区的数据。 总而言之，在所有应用程序实例中，读取和处理所有输入主题分区。<br /><br />您必须为该表提供一个名称（更确切地说，对于支持该表的内部状态存储）。 这对于支持对表的交互式查询是必需的。 如果没有提供名称，表格将不会被查询，并且会为状态存储提供一个内部名称。<br /><br />[代码参考](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)<br /><br />如果Kafka输入主题中的记录的键或值类型与配置的默认SerDes不匹配，则必须明确指定SerDes。 有关配置默认SerDes，可用SerDes和实现您自己的自定义SerDes的信息，请参阅数据类型和序列化。<br /><br />globalTable的几个变体存在于例如 指定显式SerDes。

## 流转换
KStream和KTable接口支持各种转换操作。 这些操作中的每一个都可以被转换成一个或多个连接的处理器到底层的处理器拓扑中。 由于KStream和KTable是强类型的，所有这些转换操作都被定义为通用函数，用户可以指定输入和输出数据类型。

一些KStream转换可能会生成一个或多个KStream对象，例如： - 过滤和映射KStream会生成另一个KStream - KStream上的分支可以生成多个KStream

其他一些可能会生成一个KTable对象，例如一个KStream的聚合也产生一个KTable。 这允许Kafka Streams在已经产生给下游转化操作员后的迟到记录到达时连续更新计算值。

所有KTable转换操作只能生成另一个KTable。 但是，Kafka Streams DSL确实提供了将KTable表示转换为KStream的特殊功能。 所有这些转换方法可以链接在一起组成一个复杂的处理器拓扑。

这些转换操作在以下小节中进行介绍：
- 无状态转换
- 有状态转换

### 无状态转换
无状态转换不需要状态进行处理，也不需要与流处理器相关联的状态存储。 Kafka 0.11.0和更高版本允许您实现无状态KTable转换的结果。 这允许通过交互式查询来查询结果。 为了实现KTable，下面的每个无状态操作都可以用一个可选的queryableStoreName参数来扩充。

转换|描述
----|---
分支<br /><br/>KStream → KStream[]|将基于提供的断言的KStream分支（或拆分）为一个或多个KStream实例。 （详情）<br /><br />断言按顺序进行评估。 记录被放置到第一个匹配的唯一一个输出流：如果第n个断言的计算结果为true，则记录被放置到第n个流。 如果没有断言匹配，记录将被删除。<br /><br />分支很有用，例如，可用于将记录路由到不同的下游主题。<br /><br />[代码参考](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)<br /><br />
过滤<br><br>KStream → KStream<br><br>KTable → KTable|`stream.filter`为每个元素计算布尔函数，并保留函数返回true的那些元素。 （KStream细节，KTable细节） <br /><br />[代码参考](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)<br /><br />
相反过滤器<br><br>KStream → KStream<br><br>KTable → KTable|`stream.filterNot`为每个元素计算布尔函数，并删除函数返回true的布尔函数。 （KStream细节，KTable细节） <br /><br />[代码参考](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)<br /><br />
FlatMap<br/><br/>KStream → KStream|记录一条记录并生成零个，一个或多个记录。 您可以修改记录键和值，包括它们的类型。 （细节）<br/><br/>将数据流标记为数据重新分区：在flatMap之后应用分组或连接将导致重新分区记录。 如果可能，请使用flatMapValues，而不会导致数据重新分区。 <br /><br />[代码参考](https://kafka.apache.org/10/documentation/streams/developer-guide/dsl-api.html)<br /><br />
